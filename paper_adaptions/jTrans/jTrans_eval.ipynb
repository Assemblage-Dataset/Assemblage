{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jTrans evaluation code\n",
    "\n",
    "This notebook calculates the MRR and Recall based on jTrans author's codes. Author also provides testing script in [fasteval](https://github.com/vul337/jTrans/blob/main/fasteval.py) and [eval_save.py](https://github.com/vul337/jTrans/blob/main/eval_save.py). If you have good GPU (vram>=48G) and slow Disk, this notebook will speed up evaluation speed, otherwise please use author's own code to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.get_device_name(0)\n",
    "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
    "from tokenizer import *\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from data import help_tokenize, load_paired_data, FunctionDataset_CL, FunctionDataset_CL_Load\n",
    "from transformers import AdamW\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "import data as data\n",
    "import pickle\n",
    "import sys\n",
    "from datautils_windows.playdata import DatasetBase as DatasetBase\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(net, data_loader):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        avg = []\n",
    "        total_true_positives = 0\n",
    "        total_retrieved = 0\n",
    "        total_relevant = 0\n",
    "        eval_iterator = tqdm(data_loader)\n",
    "\n",
    "        recall2 = 0\n",
    "        recall5 = 0\n",
    "        recall10 = 0\n",
    "\n",
    "        for i, (seq1, seq2, _, mask1, mask2, _) in enumerate(eval_iterator):\n",
    "            input_ids1, attention_mask1 = seq1, mask1\n",
    "            input_ids2, attention_mask2 = seq2, mask2\n",
    "\n",
    "            output1 = net(input_ids=input_ids1, attention_mask=attention_mask1)\n",
    "            anchor = output1.pooler_output\n",
    "\n",
    "            output2 = net(input_ids=input_ids2, attention_mask=attention_mask2)\n",
    "            pos = output2.pooler_output\n",
    "\n",
    "            ans = 0\n",
    "            for k in range(len(anchor)):  # Use a different loop index variable\n",
    "                vA = anchor[k:k+1]  # No need to call  again\n",
    "                sim = []\n",
    "                for j in range(len(pos)):\n",
    "                    vB = pos[j:j+1]\n",
    "                    AB_sim = F.cosine_similarity(vA, vB).item()\n",
    "                    sim.append(AB_sim)\n",
    "                \n",
    "                sim = np.array(sim)\n",
    "                y = np.argsort(sim)[::-1]  # Sort in descending order of similarity\n",
    "                posi = np.where(y == k)[0][0] + 1  # Find the position of the ground truth\n",
    "\n",
    "                # These codes are from original author's codes, which they gave explanation in their paper\n",
    "                if posi == 1:\n",
    "                    total_true_positives += 1\n",
    "                if posi <= 2:\n",
    "                    recall2 +=1\n",
    "                if posi <= 5:\n",
    "                    recall5 +=1\n",
    "                if posi <= 10:\n",
    "                    recall10 +=1\n",
    "\n",
    "                ans += 1 / posi\n",
    "            \n",
    "            # Update total counts\n",
    "            total_relevant += len(anchor)\n",
    "            total_retrieved += len(anchor)\n",
    "            \n",
    "            ans = ans / len(anchor)\n",
    "            avg.append(ans)\n",
    "\n",
    "        return avg, total_true_positives, recall2, recall5, recall10, total_relevant\n",
    "\n",
    "class BinBertModel(BertModel):\n",
    "    def __init__(self, config, add_pooling_layer=True):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "        self.embeddings.position_embeddings=self.embeddings.word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models/jTrans-finetune\" # Download from author's github\n",
    "model = BinBertModel.from_pretrained(model_path)\n",
    "\n",
    "eval_path = \"/data/jTrans/some_extract\" # Generated from previous notebook\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"./jtrans_tokenizer\")\n",
    "valid_set = FunctionDataset_CL_Load(tokenizer, eval_path, convert_jump_addr=True, opt=None) \n",
    "# FunctionDataset_CL_Load might need to be modified to adopt cross compiler data/file name convention change, \n",
    "# or simply use DataBaseCrossCompiler provided by author\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=10000, num_workers=128, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning\n",
    "\n",
    "If you see GPU OOM, please use author's code to evaluate the model or go with CPU if you have large MEM installed (but will be slower)\n",
    "If it gives out outputs, you can use the numbers to calculate Recall@* and MRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(model, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jtrans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
